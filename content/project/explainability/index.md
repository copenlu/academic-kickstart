+++
# Project title.
title = "Explainable Machine Learning"

# Short name for buttons
short_name = "Explainability"

# Date this page was created.
date = 2019-10-01T00:00:00

# Project summary to display on homepage.
summary = "Explaining relationships between inputs and outputs of black-box machine learning models"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["nlu"]

# Optional external URL for project (replaces project detail page).
external_link = ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references 
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides = "example-slides"

# Links (optional).
url_pdf = ""
url_slides = ""
url_video = ""
url_code = ""

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{icon_pack = "fab", icon="twitter", name="Follow", url = "https://twitter.com/georgecushen"}]

# Featured image
# To use, add an image named `featured.jpg/png` to your project's folder. 
[image]
  # Caption (optional)
  caption = "Photo by rawpixel on Unsplash"
  
  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "Smart"
+++

We are interested in studying method to explain relationships between inputs and outputs of black-box machine learning models, particularly in the context of challenging NLU tasks such as fact checking.

We are researching methods for explainable stance detection in the context of a <a href="https://dff.dk/en/grants/copy_of_research-leaders-2020/researchleader-14?set_language=en">DFF Sapere Aude Research Leader project</a>, and explainable fact checking as part of an <a href="https://erc.europa.eu/news-events/news/starting-grants-2022-call-results">ERC Starting Grant project</a>.

Moreover, we are investigating fair and accountable Natural Language Processing methods to understand what influences the employer images that organisations project in job ads, as part of a <a href="https://www.carlsbergfondet.dk/da/Forskningsaktiviteter/Bevillingsstatistik/Bevillingsoversigt/CF22_1461_Pia-Ingold">Carlsberg-funded project</a>.
