+++
# Project title.
title = "Social Bias Detection"

# Date this page was created.
date = 2018-04-26T00:00:00

# Project summary to display on homepage.
summary = "Detecting social biases such as gender and racial bias, in text as well as in language models"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["nlu", "bias-detection"]

# Optional external URL for project (replaces project detail page).
external_link = ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references 
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides = "example-slides"

# Links (optional).
url_pdf = ""
url_slides = ""
url_video = ""
url_code = ""

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{icon_pack = "fab", icon="twitter", name="Follow", url = "https://twitter.com/georgecushen"}]

# Featured image
# To use, add an image named `featured.jpg/png` to your project's folder. 
[image]
  # Caption (optional)
  caption = "Photo by rawpixel on Unsplash"
  
  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "Smart"
+++

We are working on studying methods to detect social biases. This includes detecting gendered language automatically using unsupervised learning methods, such as variational auto-encoders. The findings of our first paper on this (<a href="/publication/2019_acl_hoyle/">Hoyle et al., 2019</a>) have been reported by 75+ international news outlets, including <a href="https://www.forbes.com/sites/jessedamiani/2019/08/30/massive-machine-learning-study-demonstrates-gender-stereotyping-and-sexist-language-in-literature/">Forbes</a>.

We have also studied gender biases in cross-lingual settings, as well as the relationship between gender bias and attitudes towards entities on social media as part of a <a href="https://dff.dk/en/grants/database?instrument:list=all&filed_method:list=all&period:list=all&set_language=en&SearchableText=gender-biased">project funded by DFF</a>.

Moreover, in a <a href="https://www.carlsbergfondet.dk/da/Forskningsaktiviteter/Bevillingsstatistik/Bevillingsoversigt/CF22_1461_Pia-Ingold">Carlsberg-funded project</a> which started in autumn 2023, we are investigating biases which influence the employer images that organisations project in job ads.

