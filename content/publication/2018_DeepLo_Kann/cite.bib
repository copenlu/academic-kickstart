@inproceedings{kann-etal-2018-character,
    title = "Character-level Supervision for Low-resource {POS} Tagging",
    author = "Kann, Katharina  and
      Bjerva, Johannes  and
      Augenstein, Isabelle  and
      Plank, Barbara  and
      S{\o}gaard, Anders",
    booktitle = "Proceedings of the Workshop on Deep Learning Approaches for Low-Resource {NLP}",
    month = jul,
    year = "2018",
    address = "Melbourne",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-3401",
    doi = "10.18653/v1/W18-3401",
    pages = "1--11",
    abstract = "Neural part-of-speech (POS) taggers are known to not perform well with little training data. As a step towards overcoming this problem, we present an architecture for learning more robust neural POS taggers by jointly training a hierarchical, recurrent model and a recurrent character-based sequence-to-sequence network supervised using an auxiliary objective. This way, we introduce stronger character-level supervision into the model, which enables better generalization to unseen words and provides regularization, making our encoding less prone to overfitting. We experiment with three auxiliary tasks: lemmatization, character-based word autoencoding, and character-based random string autoencoding. Experiments with minimal amounts of labeled data on 34 languages show that our new architecture outperforms a single-task baseline and, surprisingly, that, on average, raw text autoencoding can be as beneficial for low-resource POS tagging as using lemma information. Our neural POS tagger closes the gap to a state-of-the-art POS tagger (MarMoT) for low-resource scenarios by 43{\%}, even outperforming it on languages with templatic morphology, e.g., Arabic, Hebrew, and Turkish, by some margin.",
}